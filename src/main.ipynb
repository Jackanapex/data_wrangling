{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries for webscraping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "# Import requried OS utility libraries for input and output file navigation\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get urls from the input folder.\n",
    "It is assumed that the input folder is at the same level with src, and the file holding the urls is called from_urls. Also it is assumed that the urls are stored and separated by newlines in the input file.\\\n",
    "It is also assumed that only the first two lines of the input file will be valid URLs. No verificiation is carried out for the input data file as it is outside the assignment scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the url list\n",
    "url_dict = {\n",
    "    'season_126': '',\n",
    "    'season_womens_seven': ''\n",
    "}\n",
    "\n",
    "# Define the import file path\n",
    "INPUT_FILE_NAME = 'from_urls'\n",
    "\n",
    "# Join the directory which is one level above this file\n",
    "# and the input folder and the input file name\n",
    "url_file_fn = os.path.join(\n",
    "    os.path.abspath('..'), \n",
    "    'input',\n",
    "    INPUT_FILE_NAME\n",
    ")\n",
    "\n",
    "# Open the file and read the urls into the url dictionary\n",
    "url_file = open(url_file_fn, 'r')\n",
    "for k, v in url_dict.items():\n",
    "    line = url_file.readline()\n",
    "    if line:\n",
    "        url_dict[k] = line.strip()\n",
    "    else:\n",
    "        pass\n",
    "url_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Request data from Wikipedia for AFL Season 126 and AFL Women's Season Seven\n",
    "The raw data will also be saved into a dictionary of two BeautifulSoup objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BeautifulSoup object dictionary\n",
    "bs_dict = {\n",
    "    'season_126': None,\n",
    "    'season_womens_seven': None\n",
    "}\n",
    "\n",
    "# Iterate through url_dict, use requests to get the website data\n",
    "# use the data to instantiate one BeautifulSoup object each\n",
    "# and save the BeautifulSoup object to bs_dict\n",
    "for k, v in url_dict.items():\n",
    "    response = requests.get(v)\n",
    "    html = response.text\n",
    "    bs_dict[k] = BeautifulSoup(html, 'html.parser')\n",
    "    response.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract from the BeautifuleSoup objects for the tables containing game rows\n",
    "Both the Pre-season and Final Series tables are considered here and scraped. It is to be noticed that only the pre-season games will have a round number. All \"rounds\" in the final series are named as Qualifying finals, Elimination finals and etc. Regardless of the different naming conventions, these final serires rounds are treated in the same way per pre-season rounds. And they will be both referred to as \"rounds\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_round_and_game_elements(soup_obj):\n",
    "    \"\"\"\n",
    "    This function extracts each game's information from a BeautifulSoup object\n",
    "    scraped from Wikipedia. Three steps are invovled here: firstly the entire object\n",
    "    is filtered to extract all rounds (both pre-season and final serires) and save them\n",
    "    in a list, then each round in the round list is further filtered to extract all games\n",
    "    and save them in another list. Finally each game in the game list is further filtered\n",
    "    to extract the required attributes. Each game's attribute information is stored in a dictionary\n",
    "    with the corresponding keys for convenient access later.\n",
    "\n",
    "    :param soup_obj: BeautifulSoup object\n",
    "    :return: a list of dictionaries, each dictionary contains the information of a game\n",
    "    \"\"\"\n",
    "\n",
    "    result_round_elements = []\n",
    "    # all round tables are with the same unique style\n",
    "    found_round_list = soup_obj.find_all('table', style='width: 100%; background-color: #f1f5fc; border: 2px solid #D0E5F5')\n",
    "    for round in found_round_list:\n",
    "        # filter for all th elements as they and only they contain round number information\n",
    "        round_number = round.tbody.find('th').text\n",
    "        # games are in the tr elements without a style\n",
    "        games = round.tbody.find_all('tr', style = lambda x: x is None)\n",
    "        for game in games:\n",
    "            # each game has 6 td elements to describe its attributes\n",
    "            game_info = game.find_all('td')\n",
    "            # some footer comments also exist as a tr element, they are not games\n",
    "            # and the uniqueness is that they contail ul elements\n",
    "            if (len(game_info) == 6) and (game_info[0].find('ul') is None) :\n",
    "                game_datetime = game_info[0]\n",
    "                home = game_info[1]\n",
    "                result = game_info[2]\n",
    "                away = game_info[3]\n",
    "                location = game_info[4]\n",
    "                # extract the attribute as strings and save in one dictionary\n",
    "                # for each game\n",
    "                result_round_elements.append(\n",
    "                    {\n",
    "                        'round_number': round_number,\n",
    "                        'datetime': game_datetime.text,\n",
    "                        'home': home.text,\n",
    "                        'result': result.text,\n",
    "                        'away': away.text,\n",
    "                        'location': location.text\n",
    "                    }\n",
    "                )\n",
    "    return result_round_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into the BeautifulSoup objects and extract all the ROUND tables under them\n",
    "# And then extract the game information and save games in one list for each season\n",
    "\n",
    "# Initialize a round_dict to store the extracted game dictionary lists\n",
    "round_dict = {\n",
    "    'season_126': [],\n",
    "    'season_womens_seven': []\n",
    "}\n",
    "\n",
    "# Iterate through the bs_dict and fill the results to round_dict\n",
    "for k, v in bs_dict.items():\n",
    "    round_dict[k] = extract_round_and_game_elements(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use RegEx to extract and cleanse the game information from the round_dict and save to a final list of strings\n",
    "The final list of strings has each game as an element, which is a string formed up by joining the RegEx-matched game attribute string results with comma delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_game_elements_to_strings(games):\n",
    "    \"\"\"\n",
    "    This function iterates through the game dictionaries in the input list\n",
    "    and uses regexes to match and format the required attribute strings.\n",
    "    The final attributes are joined together with comma delimiters for each game\n",
    "    and all game strings are saved and returned in a list\n",
    "\n",
    "    :param games: a list of dictionaries, each dictionary contains the information of a game\n",
    "    :return: a list of strings, each string contains the information of a game\n",
    "    \"\"\"\n",
    "    game_string_list = []\n",
    "    # defined the regex required to extract and format the detailed attributes\n",
    "    # the logics behind these regexes are explained in the report\n",
    "    re_pattern_dict = {\n",
    "        'round_number': r\"^Round (\\d+)( .+)*?$\",\n",
    "        'datetime': r\"^.*?(\\w+), (.+) \\((.+)\\)$\",\n",
    "        'home': r\"^(.+) \\d+\\.\\d+ \\((.+)\\)$\",\n",
    "        'result': r\"^(.+)$\",\n",
    "        'away': r\"^(.+) \\d+\\.\\d+ \\((.+)\\)$\",\n",
    "        'location': r\"^(.+) +\\(crowd\\:.(.+)\\)$\"\n",
    "    }\n",
    "    # initialize the matched result dictionary for easy access\n",
    "    matched_re_group_dict = {\n",
    "        'round_number': None,\n",
    "        'datetime': None,\n",
    "        'home': None,\n",
    "        'result': None,\n",
    "        'away': None,\n",
    "        'location': None\n",
    "    }\n",
    "    for game in games:\n",
    "        # iterate through the regex dictionary and match each attribute\n",
    "        for k, v in re_pattern_dict.items():\n",
    "            matched_re_group_dict[k] = re.match(v, game[k])\n",
    "        # join the matched results with commas\n",
    "        this_game_str = ','.join([\n",
    "            # Round Number\n",
    "            matched_re_group_dict['round_number'].group(1) \\\n",
    "                if matched_re_group_dict['round_number'] \\\n",
    "                else game['round_number'].strip(),\n",
    "            # Day of the game \n",
    "            matched_re_group_dict['datetime'].group(1),\n",
    "            # Date of the game\n",
    "            matched_re_group_dict['datetime'].group(2),\n",
    "            # Time of the game\n",
    "            matched_re_group_dict['datetime'].group(3),\n",
    "            # Home team name\n",
    "            matched_re_group_dict['home'].group(1),\n",
    "            # Home team score\n",
    "            matched_re_group_dict['home'].group(2),\n",
    "            # Result\n",
    "            matched_re_group_dict['result'].group(1),\n",
    "            # Away team name\n",
    "            matched_re_group_dict['away'].group(1),\n",
    "            # Away team score\n",
    "            matched_re_group_dict['away'].group(2),\n",
    "            # Game location\n",
    "            matched_re_group_dict['location'].group(1),\n",
    "            # Game attendees\n",
    "            matched_re_group_dict['location'].group(2).replace(',', '')\n",
    "        ])\n",
    "        game_string_list.append(this_game_str)\n",
    "    return game_string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the round_dict and extract the following information for each game\n",
    "\"\"\"\n",
    "Round Number (example: \"1\")\n",
    "Day of the game (example: \"Friday\")\n",
    "Date of the game (example: \"19-Aug\")\n",
    "Time of the game (example: \"7:50 pm\")\n",
    "First team name (example: \"Brisbane Lions\")\n",
    "First team score in points only (example: \"57\")\n",
    "First team win status (either \"def. by\" or \"def.\")\n",
    "Second team name (example: \"Melbourne\")\n",
    "Second team score in points only (example: \"115\")\n",
    "Game location (example: \"The Gabba\")\n",
    "Stadium Attendees (example: \"32172\")\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the title row for the csv file\n",
    "csv_title_row = ','.join([\n",
    "    'Round Number',\n",
    "    'Day of the game',\n",
    "    'Date of the game',\n",
    "    'Time of the game',\n",
    "    'First team name',\n",
    "    'First team score',\n",
    "    'First team win status',\n",
    "    'Second team name',\n",
    "    'Second team score',\n",
    "    'Game location',\n",
    "    'Stadium Attendees'\n",
    "])\n",
    "\n",
    "# Create the result list of csv rows, and insert the title row as the first element\n",
    "game_string_list = [csv_title_row]\n",
    "\n",
    "# Iterate through the round_dict and extract the game elements to comma-delimited strings,\n",
    "# Then append the strings to the game_string_list one by one\n",
    "for k, v in round_dict.items():\n",
    "    game_string_list.extend(extract_game_elements_to_strings(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the result to a csv output\n",
    "It is assumed that the output folder is at the same level as the src folder \\\n",
    "It is also assumed that a csv file output named scraped_game_table.csv file will exist and contain the result \\\n",
    "The file will be overwritten regardless of its existing contents and no verification of existence will be carried out\\\n",
    "since it is outside the assignment scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file path\n",
    "OUTPUT_FILE_NAME = 'scraped_game_table.csv'\n",
    "# Join the directory one level above the current file\n",
    "# together with output folder and the output file name\n",
    "scraped_game_table_fn = os.path.join(\n",
    "    os.path.abspath('..'), \n",
    "    'output',\n",
    "    OUTPUT_FILE_NAME\n",
    ")\n",
    "\n",
    "# Write the result_list to the output file\n",
    "result_file = open(scraped_game_table_fn, 'w')\n",
    "for result_str in game_string_list:\n",
    "    result_file.write(f\"{result_str}\\n\")\n",
    "result_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
